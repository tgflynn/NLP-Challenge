This project contains files related to the Metaoptimize NLP Challenge :
http://metaoptimize.com/blog/2010/11/05/nlp-challenge-find-semantically-related-terms-over-a-large-vocabulary-1m/


process.py reads a vocabulary file and a dataset file in the format defined by the Metoptimize NLP challenge
(http://metaoptimize.com/blog/2010/11/05/nlp-challenge-find-semantically-related-terms-over-a-large-vocabulary-1m/)
and generates an output file consisting of a set of lines where each line consists of a space separated list of words,
The first word on each line contains a word from the vocabulary list.  The remaining words on the line consist of
those words from the dataset which have been found to co-occur with the vocabulary word.  They are in descreasing
order by co-occurrence frequency.

USAGE:

Run semantic similarity algorithm
./process.py -d <dataset file> -v <vocabulary file> -o <output file>

Filter dataset file - filters non-alpha words out of a dataset file
./process.py -f <dataset file> -o <output file>

Create a new vocabulary file from a dataset file
./process.py -d <dataset file> -o <output file> -m


score.py scores an output file based on Word Net (http://wordnet.princeton.edu) synset similarity scores.

USAGE:

./score.py -i <output file>

See the file license.txt for copyright information and license terms.

DEPENDENCIES:

score.py requires that the nltk toolkit be installed (http://nltk.googlecode.com).

You also need to download the WordNet data files before running score.py.  As follows :

python
>>> import nltk
>>> nltk.download()
Downloader>  d
Downloader>  all
Downloader>  q
>>> quit()
